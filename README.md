# Classification-of-Research-Papers

ArXiv has been serving the public and research communities for nearly 30 years by providing open access to scholarly articles ranging from the vast branches of physics to the many subdisciplines of computer science and everything in between, including math, statistics, electrical engineering, quantitative biology, and economics. This vast repository of data provides significant, if at times overwhelming, depth.

A repository of 1.7 million articles, with relevant features such as article titles, authors, categories, abstracts, full text PDFs, and more.

# Results:

As we can see from the below table all the metrics score of all the models we can say that all the models look to be performing great with an accuracy going above 80%. According to the table, Deep learning with Bert pretrained model has the highest accuracy of 91%.

![image](https://user-images.githubusercontent.com/50734928/189012031-c9990034-35cb-484a-8b8e-0bd89eb2608b.png)

# Conclusion

In this project, we discussed how to apply various NLP models to a text classification use case. I compared three popular approaches: Bag-of-Words with Tfidf, Word Embedding with Word2Vec, and Language model with BERT. With such great accuracy score we can say that the best model can be used for classifying papers into different categories.
